{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XVAigB3DI3d1qUBDBGOyZQN_Mr_6RTh3","timestamp":1749183011430}],"gpuType":"T4","authorship_tag":"ABX9TyPRJUs71Ll2FNV2o0W1gKad"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Configuração"],"metadata":{"id":"3AU-4EqEPrcF"}},{"cell_type":"markdown","source":["Importa dados sintéticos"],"metadata":{"id":"77LzQv2ittKY"}},{"cell_type":"code","source":["# Instalar pacotes necessários\n","!pip install transformers datasets peft bitsandbytes accelerate --quiet\n","!pip install sentencepiece --quiet\n","!pip install --upgrade transformers\n","\n","# Imports principais\n","import requests\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, pipeline\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","import csv\n","\n","# Download do CSV do Drive\n","file_id = '1aRRsf2lvAawmN4Jmr4Vn0V17Y7FO6z2r'\n","url = f'https://drive.google.com/uc?export=download&id={file_id}'\n","\n","response = requests.get(url)\n","if response.status_code == 200:\n","    csv_text = response.text\n","    with open(\"dataset.csv\", \"w\", encoding=\"utf-8\") as f:\n","        f.write(csv_text)\n","    print(\"Arquivo baixado e salvo como dataset.csv\")\n","else:\n","    raise Exception(f\"Erro ao acessar arquivo: {response.status_code}\")\n","\n","# Carregar o CSV em DataFrame\n","# Lista para armazenar os dados\n","dados = []\n","\n","# Abrir e ler o arquivo CSV manualmente\n","with open(\"dataset.csv\", encoding=\"utf-8\") as f:\n","    leitor = csv.reader(f, delimiter=',', quotechar='\"')\n","    for linha in leitor:\n","        # Ignora linhas mal formatadas (ex: incompletas)\n","        if len(linha) == 2:\n","            dados.append(linha)\n","\n","# Criar o DataFrame\n","df = pd.DataFrame(dados, columns=[\"pergunta\", \"resposta\"])\n","\n","# Verificar os dados\n","print(df.head())\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig, pipeline\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","import torch\n","\n","# Pré-processamento\n","def preprocess(row):\n","    return f\"Pergunta: {row['pergunta']} Resposta: {row['resposta']}\"\n","\n","df[\"text\"] = df.apply(preprocess, axis=1)\n","dataset = Dataset.from_pandas(df[[\"text\"]])\n","\n","# Tokenizador\n","model_name = \"bigscience/bloom-560m\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# GPT2 não tem token de padding por padrão\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# Função de tokenização corrigida\n","def tokenize_function(examples):\n","    return tokenizer(\n","        examples[\"text\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=128\n","    )\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","\n","# Quantização com BitsAndBytesConfig (substitui load_in_8bit)\n","bnb_config = BitsAndBytesConfig(\n","    load_in_8bit=True,\n","    llm_int8_threshold=6.0,\n","    llm_int8_skip_modules=None,\n",")\n","\n","# Modelo\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")\n","\n","model = prepare_model_for_kbit_training(model)\n","\n","# Configuração LoRA\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\"query_key_value\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","# Argumentos de treino\n","training_args = TrainingArguments(\n","    output_dir=\"./qlora-br-china\",\n","    per_device_train_batch_size=8,\n","    gradient_accumulation_steps=2,\n","    num_train_epochs=3,\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-4,\n","    fp16=True,\n","    save_total_limit=1,\n","    report_to=\"none\",\n","    push_to_hub=False,\n","    remove_unused_columns=False,\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=lambda data: {\n","        \"input_ids\": torch.tensor([f[\"input_ids\"] for f in data]),\n","        \"attention_mask\": torch.tensor([f[\"attention_mask\"] for f in data]),\n","        \"labels\": torch.tensor([f[\"input_ids\"] for f in data]),  # causal LM usa input_ids como labels\n","    },\n",")\n","\n","# Treinamento\n","trainer.train()\n","\n","# Salvar modelo LoRA treinado\n","model.save_pretrained(\"./qlora-br-china\")\n","\n","# -------- Inferência --------\n","\n","# Modelo original\n","pipe_orig = pipeline(\"text-generation\", model=model_name, tokenizer=tokenizer, device=0)\n","\n","# Modelo com QLoRA\n","pipe_qlora = pipeline(\"text-generation\", model=\"./qlora-br-china\", tokenizer=tokenizer, device=0)\n","perguntas = [\n","    \"Qual é a importância do acordo de exportação de café entre Brasil e China?\",\n","    \"Como a parceria China-Brasil pode impactar o setor de tecnologia em 2025?\",\n","    \"Quais são os principais investimentos chineses previstos no Brasil para 2025?\",\n","    \"Como o comércio bilateral entre Brasil e China deve evoluir até 2025?\",\n","    \"Quais setores brasileiros terão maior benefício da cooperação com a China em 2025?\",\n","    \"Qual o papel da China na infraestrutura brasileira até 2025?\",\n","    \"Como a relação diplomática entre Brasil e China deve se fortalecer em 2025?\",\n","    \"Quais desafios podem surgir na relação econômica entre Brasil e China em 2025?\",\n","    \"Como o acordo comercial com a China pode afetar a agricultura brasileira em 2025?\",\n","    \"Quais oportunidades de inovação surgirão com a cooperação Brasil-China até 2025?\"\n","]\n","\n","def extrair_resposta_curta(texto):\n","    parte_resposta = texto.split(\"Resposta:\")[-1].strip()\n","    primeira_frase = parte_resposta.split('.')[0]\n","    return primeira_frase + '.'\n","\n","for pergunta in perguntas:\n","    entrada = f\"Pergunta: {pergunta} Resposta:\"\n","\n","    print(f\"\\nPergunta: {pergunta}\")\n","\n","    res_orig = pipe_orig(entrada, max_length=50, do_sample=True, top_p=0.9, temperature=0.8)\n","    resposta_orig = extrair_resposta_curta(res_orig[0][\"generated_text\"])\n","    print(\"Resposta modelo original:\", resposta_orig)\n","\n","    res_qlora = pipe_qlora(entrada, max_length=50, do_sample=True, top_p=0.9, temperature=0.8)\n","    resposta_qlora = extrair_resposta_curta(res_qlora[0][\"generated_text\"])\n","    print(\"Resposta modelo QLoRA:\", resposta_qlora)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHQiN5mg4Ood","executionInfo":{"status":"ok","timestamp":1749182788312,"user_tz":240,"elapsed":183543,"user":{"displayName":"Matteo Freitas Reis","userId":"15786923725239010380"}},"outputId":"aaf1d140-664b-43b3-b946-7fa034db76ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n","Collecting transformers\n","  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.52.3\n","    Uninstalling transformers-4.52.3:\n","      Successfully uninstalled transformers-4.52.3\n","Successfully installed transformers-4.52.4\n"]}]}]}